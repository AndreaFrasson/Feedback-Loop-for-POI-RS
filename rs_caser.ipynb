{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "from logging import getLogger\n",
    "from recbole.model.general_recommender import BPR, Pop\n",
    "from recbole.model.sequential_recommender import Caser\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger\n",
    "\n",
    "import torch\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "import make_atomic_files as at\n",
    "\n",
    "## Tuning\n",
    "from recbole.trainer import HyperTuning\n",
    "from recbole.utils import init_seed\n",
    "import os\n",
    "from recbole.utils import get_model, get_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "at.og_atomic_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(config_dict=None, config_file_list=None):\n",
    "    k = 10\n",
    "\n",
    "    config_dict = {\n",
    "        'model': 'Caser',\n",
    "        'train_neg_sample_args': None,\n",
    "        'seed': 1234,\n",
    "        'epochs': 10,\n",
    "        'reproducibility': True,\n",
    "        'topk': 10,\n",
    "        'use_gpu': True\n",
    "    } \n",
    "\n",
    "    config = Config(config_dict=config_dict, config_file_list=['foursquare_general.yaml'])\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "    dataset = create_dataset(config)\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "    model_name = config['model']\n",
    "    model = get_model(model_name)(config, train_data._dataset).to(config['device'])\n",
    "    trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'best_valid_score': best_valid_score,\n",
    "        'valid_score_bigger': config['valid_metric_bigger'],\n",
    "        'best_valid_result': best_valid_result,\n",
    "        'test_result': test_result\n",
    "    }\n",
    "\n",
    "hp = HyperTuning(objective_function=objective_function, algo='random', early_stop=10,\n",
    "                max_evals=100, params_file='caser.hyper', fixed_config_file_list=['foursquare_general.yaml'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_history(inter):\n",
    "\n",
    "    visits = []\n",
    "    set_uid = set(inter['uid:token'])\n",
    "    for u in set_uid:\n",
    "        visits.append(inter[inter['uid:token'] == u]['venue_id:token'].values.tolist())\n",
    "    \n",
    "    return np.array(visits)\n",
    "\n",
    "inter = pd.read_csv('foursquare/foursquare.inter', sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "hp.run()\n",
    "params = hp.best_params\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train General Recommendation\n",
    "params = {'dynamic': False, 'embedding_size': 128, 'learning_rate': 0.07885866707608949, 'mlp_hidden_size': '[64,64,64]', 'sample_num': 5, 'train_batch_size': 4096}\n",
    "# configurations initialization\n",
    "k = 10\n",
    "\n",
    "config = Config(model='BPR', dataset='foursquare', config_file_list=['foursquare_general.yaml'], config_dict = params)\n",
    "\n",
    "# init random seed\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "# dataset creating and filtering\n",
    "dataset = create_dataset(config)\n",
    "\n",
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "model = Pop(config, train_data.dataset).to(config['device'])\n",
    "\n",
    "# trainer loading and initialization\n",
    "trainer = Trainer(config, model)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "\n",
    "# model evaluation\n",
    "test_result = trainer.evaluate(test_data)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make prediction\n",
    "visits = get_history(inter)\n",
    "\n",
    "unique_users = list(set(inter['uid:token']))\n",
    "unique_locations = list(set(inter['venue_id:token']))\n",
    "\n",
    "current_time = max(inter['timestamp:token'])+1\n",
    "\n",
    "#make prediction for users\n",
    "input_inter = Interaction({\n",
    "    'uid': torch.tensor(unique_users),\n",
    "    'venue_id': torch.tensor(visits)\n",
    "})\n",
    "\n",
    "with torch.no_grad():\n",
    "    scores = model.full_sort_predict(input_inter).reshape((len(unique_users), -1))\n",
    "\n",
    "#length |items| + 1 because of the padding\n",
    "print(scores.shape)\n",
    "\n",
    "# get the 10 items with highest scores\n",
    "rec_list = np.argsort(scores, axis = 1)[:, -k:]\n",
    "\n",
    "# select one item at random for each user\n",
    "def random_choice(a):\n",
    "    # select one item, but then translated back\n",
    "    r_c = np.random.choice(a, 1)\n",
    "    return int(r_c) - 1\n",
    "\n",
    "random_item = np.apply_along_axis(random_choice, 1, rec_list)\n",
    "print(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add new values in the dataset\n",
    "new_locations = pd.DataFrame({'uid:token': unique_users, 'venue_id:token':random_item.tolist(), 'timestamp:token':[current_time]*len(random_item)}, columns=['uid:token', 'venue_id:token', 'timestamp:token'])\n",
    "new_locations.head()\n",
    "\n",
    "inter = pd.concat([inter, new_locations], axis = 0).reset_index(drop = True)\n",
    "inter.sort_values(by=['uid:token', 'timestamp:token'], inplace=True)\n",
    "\n",
    "unique_users = list(set(inter['uid:token']))\n",
    "unique_locations = list(set(inter['venue_id:token']))\n",
    "\n",
    "inter.to_csv('foursquare/foursquare.inter', index=False, sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
