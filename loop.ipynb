{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "from logging import getLogger\n",
    "from recbole.model.general_recommender import BPR\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger\n",
    "\n",
    "import torch\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config_dict, k = 10):\n",
    "    # configurations initialization\n",
    "\n",
    "    config = Config(model='BPR', dataset='foursquare', config_file_list=['foursquare_general.yaml'], config_dict = config_dict)\n",
    "\n",
    "    # init random seed\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "    # logger initialization\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "\n",
    "    # write config info into log\n",
    "    logger.info(config)\n",
    "\n",
    "    # dataset creating and filtering\n",
    "    dataset = create_dataset(config)\n",
    "    logger.info(dataset)\n",
    "\n",
    "    # dataset splitting\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # model loading and initialization\n",
    "    model = BPR(config, train_data.dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = Trainer(config, model)\n",
    "\n",
    "    # model training\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data, verbose=False)\n",
    "\n",
    "    # model evaluation\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "    print(test_result)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def get_history(inter):\n",
    "    visits = []\n",
    "    set_uid = set(inter['uid:token'])\n",
    "    for u in set_uid:\n",
    "        visits.append(inter[inter['uid:token'] == u]['venue_id:token'].values.tolist())\n",
    "    \n",
    "    return visits\n",
    "\n",
    "\n",
    "\n",
    "def predict_k(model, users, visits, locations, k): \n",
    "    #make prediction for users\n",
    "\n",
    "    input_inter = Interaction({\n",
    "        'uid': torch.tensor(users),\n",
    "        'venue_id': torch.tensor(visits),\n",
    "    })\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = model.full_sort_predict(input_inter).reshape((len(users), -1))\n",
    "\n",
    "    # get the 10 items with highest scores\n",
    "    return np.argsort(scores, axis = 1)[:, -k:]\n",
    "\n",
    "\n",
    "\n",
    "# select one item at random for each user\n",
    "def random_choice(a):\n",
    "    # select one item, but then translate it back\n",
    "    r_c = np.random.choice(a, 1)\n",
    "    return int(r_c) - 1\n",
    "\n",
    "\n",
    "\n",
    "def new_atomic_files(interaction):\n",
    "    try:\n",
    "        interaction.to_csv('foursquare/foursquare.inter', index=False, sep = '\\t')\n",
    "        print('saved')\n",
    "    except:\n",
    "        print('Error saving the interaction file.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def single_loop(interaction, m, config_dict, users, locations, k):\n",
    "    # for m iterations, predict the new locations using the same model\n",
    "    i = 0\n",
    "\n",
    "    while i < m:\n",
    "        print('')\n",
    "        print('--------- iteration number: ', i)\n",
    "        print('')\n",
    "\n",
    "        # train the model\n",
    "        model = train_model(config_dict)\n",
    "\n",
    "        #get the users' history\n",
    "        visits = get_history(interaction)\n",
    "\n",
    "        #recommendation list\n",
    "        rec_list = predict_k(model, users, visits, locations, k)\n",
    "\n",
    "        #select one item in the list\n",
    "        random_item = np.apply_along_axis(random_choice, 1, rec_list)\n",
    "\n",
    "        ### update the training set\n",
    "        current_time = max(interaction['timestamp:token'])+1\n",
    "        new_locations = pd.DataFrame({'uid:token': users, 'venue_id:token':random_item.tolist(), \n",
    "                                      'timestamp:token':[current_time]*len(random_item)}, \n",
    "                                      columns=['uid:token', 'venue_id:token', 'timestamp:token'])\n",
    "        \n",
    "        interaction = pd.concat([interaction, new_locations], axis = 0).reset_index(drop = True)\n",
    "        interaction.sort_values(by=['uid:token', 'timestamp:token'], inplace=True)\n",
    "\n",
    "        new_atomic_files(interaction)\n",
    "\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- iteration number:  0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 May 08:31    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 1234\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /Users/andreafrasson/Desktop/tesi/Feedback-Loop-for-POI-RS/foursquare\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 10\n",
      "train_batch_size = 4096\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = uid\n",
      "ITEM_ID_FIELD = venue_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['uid', 'venue_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "17 May 08:31    INFO  foursquare\n",
      "The number of users: 1084\n",
      "Average actions of users: 100.0\n",
      "The number of items: 27899\n",
      "Average actions of items: 3.8819987095849164\n",
      "The number of inters: 108300\n",
      "The sparsity of the dataset: 99.6418948740905%\n",
      "Remain Fields: ['uid', 'venue_id', 'timestamp']\n",
      "17 May 08:31    INFO  [Training]: train_batch_size = [4096] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "17 May 08:31    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "17 May 08:31    INFO  BPR(\n",
      "  (user_embedding): Embedding(1084, 64)\n",
      "  (item_embedding): Embedding(27899, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 1854912\n",
      "17 May 08:31    INFO  Loading model structure and parameters from saved/BPR-May-17-2024_08-31-09.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('recall@10', 0.398), ('mrr@10', 0.3578), ('ndcg@10', 0.3673), ('hit@10', 0.398), ('precision@10', 0.0398)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8_/mkx2sfs13pqgtr19k0_pc89h0000gn/T/ipykernel_1530/361195557.py:68: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return int(np.random.choice(a, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "config_dict = {\n",
    "    #environment settings\n",
    "    'seed': 1234,\n",
    "    'reproducibility': True,\n",
    "    'data_path': os.getcwd(), \n",
    "    'topk': k\n",
    "}\n",
    "\n",
    "m = 3\n",
    "inter = pd.read_csv('inter.csv')\n",
    "\n",
    "unique_users = list(set(inter['uid:token']))\n",
    "unique_locations = list(set(inter['venue_id:token']))\n",
    "\n",
    "single_loop(inter, 1, config_dict, unique_users, unique_locations, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid:token</th>\n",
       "      <th>venue_id:token</th>\n",
       "      <th>timestamp:token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1511</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6720</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108295</th>\n",
       "      <td>1083</td>\n",
       "      <td>623</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108296</th>\n",
       "      <td>1083</td>\n",
       "      <td>1313</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108297</th>\n",
       "      <td>1083</td>\n",
       "      <td>4567</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108298</th>\n",
       "      <td>1083</td>\n",
       "      <td>4127</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108299</th>\n",
       "      <td>1083</td>\n",
       "      <td>1313</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid:token  venue_id:token  timestamp:token\n",
       "0               1           33236                0\n",
       "1               1             791                1\n",
       "2               1            1511                2\n",
       "3               1            6720                3\n",
       "4               1             255                4\n",
       "...           ...             ...              ...\n",
       "108295       1083             623               95\n",
       "108296       1083            1313               96\n",
       "108297       1083            4567               97\n",
       "108298       1083            4127               98\n",
       "108299       1083            1313               99\n",
       "\n",
       "[108300 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/andreafrasson/Desktop/tesi/Feedback-Loop-for-POI-RS'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
